<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width"><link rel=icon type=image/ico href=https://bnm3k.github.io//favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://bnm3k.github.io//favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://bnm3k.github.io//favicon-32x32.png><link rel=icon type=image/png sizes=192x192 href=https://bnm3k.github.io//android-chrome-192x192.png><link rel=apple-touch-icon sizes=180x180 href=https://bnm3k.github.io//apple-touch-icon.png><meta name=description content><title>PostgreSQL to Iceberg Snapshot Sync (Using DuckDB) | bnm 3000
</title><link rel=canonical href=https://bnm3k.github.io/blog/postgres-iceberg-sync-duckdb/><meta property="og:url" content="https://bnm3k.github.io/blog/postgres-iceberg-sync-duckdb/"><meta property="og:site_name" content="bnm 3000"><meta property="og:title" content="PostgreSQL to Iceberg Snapshot Sync (Using DuckDB)"><meta property="og:description" content="Query PG using DuckDB, copy table data into iceberg"><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="notes"><meta property="article:published_time" content="2025-01-02T00:00:00+00:00"><meta property="article:modified_time" content="2025-01-02T00:00:00+00:00"><meta property="article:tag" content="PostgreSQL"><meta property="article:tag" content="DuckDB"><link rel=stylesheet href=/assets/combined.min.186794b3399a702d3092949042cdc215dea303c17e71e7c0254768448de11db8.css media=all></head><body class=light><div class=content><header><div class=header><div class=flex><p class=small><a href=/>/home</a></p><p class=small><a href=/posts>/posts</a></p><p class=small><a href=/notes>/notes</a></p><p class=small><a href=/tags>/tags</a></p></div></div></header><main class=main><div class=breadcrumbs><a href=/>Home</a>
<span class=breadcrumbs-separator>> </span><a href=/notes/>Notes</a>
<span class=breadcrumbs-separator>> </span><a class=breadcrumbs-current href=/blog/postgres-iceberg-sync-duckdb/>PostgreSQL to Iceberg Snapshot Sync (Using DuckDB)</a></div><div><div class=single-intro-container><h1 class=single-title>PostgreSQL to Iceberg Snapshot Sync (Using DuckDB)</h1><p class=single-readtime><time datetime=2025-01-02T00:00:00+00:00>January 2, 2025</time>
&nbsp; Â· &nbsp;
2 min read</p></div><div class=single-tags><span><a href=https://bnm3k.github.io/tags/postgresql/>#PostgreSQL</a>
</span><span><a href=https://bnm3k.github.io/tags/duckdb/>#DuckDB</a></span></div><div class=single-content><p>Why sync from Postgres to Iceberg: you want an analytics optimized snapshot of
your data to carry out OLAP-style queries on. This can be accomplished using
DuckDB plus a bit of glue code. Specifically, this post relies on the following
key features of DuckDB:</p><ul><li>DuckDB&rsquo;s ability to query and read data directly from Postgres via the
<a href=https://duckdb.org/docs/extensions/postgres.html>PostgreSQL Extension</a></li><li>DuckDB&rsquo;s ability to output Arrow data efficiently (see
<a href=https://duckdb.org/2021/12/03/duck-arrow.html>DuckDB Quacks Arrow: A Zero-copy Data Integration between Apache Arrow and DuckDB</a>)</li></ul><p>I&rsquo;ll also use Python and PyIceberg. For the iceberg catalog, I&rsquo;ll use sqlite.
Let&rsquo;s get right to it.</p><p>First, let&rsquo;s set up the catalog:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-weight:700>import</span> <span style=font-weight:700>os</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=font-weight:700>from</span> <span style=font-weight:700>pyiceberg.catalog.sql</span> <span style=font-weight:700>import</span> SqlCatalog
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>warehouse_path = os.path.abspath(<span style=font-style:italic>&#34;./warehouse&#34;</span>)
</span></span><span style=display:flex><span>os.makedirs(warehouse_path, exist_ok=<span style=font-weight:700>True</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>os.makedirs(warehouse_path, exist_ok=<span style=font-weight:700>True</span>)
</span></span><span style=display:flex><span>catalog = SqlCatalog(
</span></span><span style=display:flex><span>    <span style=font-style:italic>&#34;default&#34;</span>,
</span></span><span style=display:flex><span>    **{
</span></span><span style=display:flex><span>        <span style=font-style:italic>&#34;uri&#34;</span>: <span style=font-style:italic>f</span><span style=font-style:italic>&#34;sqlite:///</span><span style=font-weight:700;font-style:italic>{</span>warehouse_path<span style=font-weight:700;font-style:italic>}</span><span style=font-style:italic>/catalog.db&#34;</span>,
</span></span><span style=display:flex><span>        <span style=font-style:italic>&#34;warehouse&#34;</span>: <span style=font-style:italic>f</span><span style=font-style:italic>&#34;file://</span><span style=font-weight:700;font-style:italic>{</span>warehouse_path<span style=font-weight:700;font-style:italic>}</span><span style=font-style:italic>&#34;</span>,
</span></span><span style=display:flex><span>    },
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><p>Next, let&rsquo;s set up duckdb and connect it to postgres:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-weight:700>import</span> <span style=font-weight:700>duckdb</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>conn = duckdb.connect(<span style=font-style:italic>&#34;:memory:&#34;</span>)
</span></span><span style=display:flex><span>db_name = os.getenv(<span style=font-style:italic>&#34;PG_DATABASE&#34;</span>)
</span></span><span style=display:flex><span>pg = {
</span></span><span style=display:flex><span>    <span style=font-style:italic>&#34;database&#34;</span>: db_name,
</span></span><span style=display:flex><span>    <span style=font-style:italic>&#34;user&#34;</span>: os.getenv(<span style=font-style:italic>&#34;PG_USER&#34;</span>)
</span></span><span style=display:flex><span>    <span style=font-style:italic>&#34;password&#34;</span>: os.getenv(<span style=font-style:italic>&#34;PG_PASSWORD&#34;</span>),
</span></span><span style=display:flex><span>    <span style=font-style:italic>&#34;host&#34;</span>: os.getenv(<span style=font-style:italic>&#34;PG_HOST&#34;</span>)
</span></span><span style=display:flex><span>    <span style=font-style:italic>&#34;port&#34;</span>: os.getenv(<span style=font-style:italic>&#34;PG_PORT&#34;</span>)
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>conn.execute(<span style=font-style:italic>&#34;install postgres&#34;</span>)
</span></span><span style=display:flex><span>conn.execute(<span style=font-style:italic>&#34;load postgres&#34;</span>)
</span></span><span style=display:flex><span>conn.execute(
</span></span><span style=display:flex><span>    <span style=font-style:italic>&#34;&#34;&#34;attach &#39;host=</span><span style=font-weight:700;font-style:italic>{}</span><span style=font-style:italic> port=</span><span style=font-weight:700;font-style:italic>{}</span><span style=font-style:italic> dbname=</span><span style=font-weight:700;font-style:italic>{}</span><span style=font-style:italic> user=</span><span style=font-weight:700;font-style:italic>{}</span><span style=font-style:italic> password=</span><span style=font-weight:700;font-style:italic>{}</span><span style=font-style:italic>&#39;
</span></span></span><span style=display:flex><span><span style=font-style:italic>    as </span><span style=font-weight:700;font-style:italic>{}</span><span style=font-style:italic> (type postgres, read_only)
</span></span></span><span style=display:flex><span><span style=font-style:italic>    &#34;&#34;&#34;</span>.format(
</span></span><span style=display:flex><span>        pg[<span style=font-style:italic>&#34;host&#34;</span>],
</span></span><span style=display:flex><span>        pg[<span style=font-style:italic>&#34;port&#34;</span>],
</span></span><span style=display:flex><span>        pg[<span style=font-style:italic>&#34;database&#34;</span>],
</span></span><span style=display:flex><span>        pg[<span style=font-style:italic>&#34;user&#34;</span>],
</span></span><span style=display:flex><span>        pg[<span style=font-style:italic>&#34;password&#34;</span>],
</span></span><span style=display:flex><span>        db_name,
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><p>Let&rsquo;s retrieve the schemas in Postgres plus the tables within those schemas:</p><ul><li>we&rsquo;re using <code>postgres_query</code> which is a duckdb function that runs the query
it&rsquo;s supplied with directly in postgres. Single quote strings have to be
escaped by repeating the single quote twice</li><li>in postgres, we can get the list of schemas via querying the
<code>information_schema.schemata</code> view, e.g.
<code>select * from information_schema.schemata</code></li><li><code>pg_catalog</code>, <code>pg_toast</code>, <code>information_schema</code> are schemas internal to
postgres that we need to filter out</li><li>once we have a schema name, we can get the tables within that schema via
querying the <code>pg_tables</code> system view</li></ul><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-style:italic># get schemas</span>
</span></span><span style=display:flex><span>pg_query = <span style=font-style:italic>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=font-style:italic>select schema_name
</span></span></span><span style=display:flex><span><span style=font-style:italic>from information_schema.schemata
</span></span></span><span style=display:flex><span><span style=font-style:italic>where schema_name not in (&#39;&#39;pg_catalog&#39;&#39;, &#39;&#39;pg_toast&#39;&#39;, &#39;&#39;information_schema&#39;&#39;)
</span></span></span><span style=display:flex><span><span style=font-style:italic> &#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>res = conn.sql(<span style=font-style:italic>f</span><span style=font-style:italic>&#34;select * from postgres_query(&#39;</span><span style=font-weight:700;font-style:italic>{</span>db_name<span style=font-weight:700;font-style:italic>}</span><span style=font-style:italic>&#39;, &#39;</span><span style=font-weight:700;font-style:italic>{</span>pg_query<span style=font-weight:700;font-style:italic>}</span><span style=font-style:italic>&#39;)&#34;</span>)
</span></span><span style=display:flex><span>schema_to_tables = {r[0]: [] <span style=font-weight:700>for</span> r <span style=font-weight:700>in</span> res.fetchall()}
</span></span><span style=display:flex><span><span style=font-weight:700>for</span> s <span style=font-weight:700>in</span> schema_to_tables:
</span></span><span style=display:flex><span>    res = conn.sql(
</span></span><span style=display:flex><span>        <span style=font-style:italic>f</span><span style=font-style:italic>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=font-style:italic>    select * from postgres_query(&#39;</span><span style=font-weight:700;font-style:italic>{</span>db_name<span style=font-weight:700;font-style:italic>}</span><span style=font-style:italic>&#39;,
</span></span></span><span style=display:flex><span><span style=font-style:italic>        &#39;select tablename from pg_tables where schemaname=&#39;&#39;</span><span style=font-weight:700;font-style:italic>{</span>s<span style=font-weight:700;font-style:italic>}</span><span style=font-style:italic>&#39;&#39;&#39;)&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>    schema_to_tables[s] = [r[0] <span style=font-weight:700>for</span> r <span style=font-weight:700>in</span> res.fetchall()]
</span></span></code></pre></div><p>Finally, let&rsquo;s sync from Postgres to Iceberg. Note that the sync&rsquo;s being carried
out within a transaction:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=font-weight:700>with</span> conn.begin() <span style=font-weight:700>as</span> tx:
</span></span><span style=display:flex><span>    <span style=font-weight:700>for</span> schema, tables <span style=font-weight:700>in</span> schema_to_tables.items():
</span></span><span style=display:flex><span>        catalog.create_namespace(schema)
</span></span><span style=display:flex><span>        <span style=font-weight:700>for</span> tbl_name <span style=font-weight:700>in</span> tables:
</span></span><span style=display:flex><span>            full_tbl_name = <span style=font-style:italic>f</span><span style=font-style:italic>&#34;</span><span style=font-weight:700;font-style:italic>{</span>schema<span style=font-weight:700;font-style:italic>}</span><span style=font-style:italic>.</span><span style=font-weight:700;font-style:italic>{</span>tbl_name<span style=font-weight:700;font-style:italic>}</span><span style=font-style:italic>&#34;</span>
</span></span><span style=display:flex><span>            df = tx.sql(<span style=font-style:italic>f</span><span style=font-style:italic>&#34;table </span><span style=font-weight:700;font-style:italic>{</span>db_name<span style=font-weight:700;font-style:italic>}</span><span style=font-style:italic>.</span><span style=font-weight:700;font-style:italic>{</span>full_tbl_name<span style=font-weight:700;font-style:italic>}</span><span style=font-style:italic>&#34;</span>).arrow()
</span></span><span style=display:flex><span>            print(df)
</span></span><span style=display:flex><span>            table = catalog.create_table(full_tbl_name, schema=df.schema)
</span></span><span style=display:flex><span>            table.append(df)
</span></span><span style=display:flex><span>    tx.commit()
</span></span></code></pre></div></div><div class=single-pagination><hr><div class=flex><div class=single-pagination-next></div><div class=single-pagination-prev><div class=single-pagination-container-prev><div class=single-pagination-text><a href=/blog/pg-arrays-constraints-immutable-functions/>Arrays, Constraints & Immutable Functions</a></div><div class=single-pagination-text>â</div></div></div></div><hr></div><div class=back-to-top><a href=#top>back to top</a></div></div></main></div><footer><p>&mldr;</p></footer></body><script>function isAuto(){return document.body.classList.contains("auto")}function setTheme(){if(!isAuto())return;document.body.classList.remove("auto");let e="light";window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches&&(e="dark"),document.body.classList.add(e)}function invertBody(){document.body.classList.toggle("dark"),document.body.classList.toggle("light")}isAuto()&&window.matchMedia("(prefers-color-scheme: dark)").addListener(invertBody),setTheme()</script></html>